<?xml version="1.0" ?>
<Simulation verbosity="debug">
  <TestInfo>
    <name>framework/Optimizers.Basic</name>
    <author>talbpaul</author>
    <created>2020-01-29</created>
    <classesTested>Optimizer</classesTested>
    <description>
      This is the most basic test of the Optimizer. It employs finite difference for the gradient
      estimation, gradient history for the step determination, and strict improvement acceptance. It
      converges only on the number of samples taken with a single trajectory on the Beale function. It
      also demonstrates typical outstream options for optimization. It also tests passing through
      constants and functions.
    </description>
    <analytic>
      This test uses Beale's function, which is documented in the analytic tests documentation under
      the Optimizer functions section.
    </analytic>
  </TestInfo>

  <RunInfo>
    <WorkingDir>Basic</WorkingDir>
    <Sequence>optimize, print</Sequence>
  </RunInfo>

  <Steps>
    <MultiRun name="optimize">
      <Input class="DataObjects" type="PointSet">dummyIN</Input>
      <Model class="Models" type="ExternalModel">beale</Model>
      <Optimizer class="Optimizers" type="GradientDescent">opter</Optimizer>
      <SolutionExport class="DataObjects" type="PointSet">opt_export</SolutionExport>
      <Output class="DataObjects" type="PointSet">optOut</Output>
      <Output class="OutStreams" type="Print">opt_export</Output>
    </MultiRun>
    <IOStep name="print">
      <Input class="DataObjects" type="PointSet">opt_export</Input>
      <Input class="DataObjects" type="PointSet">optOut</Input>
      <Output class="OutStreams" type="Print">opt_export</Output>
      <Output class="OutStreams" type="Print">optOut</Output>
      <Output class="OutStreams" type="Plot">opt_path</Output>
    </IOStep>
  </Steps>

  <Distributions>
    <Uniform name='beale_dist'>
      <lowerBound>-4.5</lowerBound>
      <upperBound>4.5</upperBound>
    </Uniform>
  </Distributions>

  <Functions>
    <External file="var_func.py" name="var_func">
      <variables>x,y,const</variables>
    </External>
  </Functions>

  <Optimizers>
    <GradientDescent name="opter">
      <objective>ans</objective>
      <variable name="x">
        <distribution>beale_dist</distribution>
        <initial>-2</initial>
      </variable>
      <variable name="y">
        <distribution>beale_dist</distribution>
        <initial>-2</initial>
      </variable>
      <variable name="func">
        <function>var_func</function>
      </variable>
      <TargetEvaluation class="DataObjects" type="PointSet">optOut</TargetEvaluation>
      <samplerInit>
        <limit>100</limit>
        <initialSeed>42</initialSeed>
        <writeSteps>every</writeSteps>
      </samplerInit>
      <gradient>
        <FiniteDifference/>
      </gradient>
      <stepSize>
        <GradientHistory>
          <growthFactor>1.25</growthFactor>
          <shrinkFactor>1.5</shrinkFactor>
        </GradientHistory>
      </stepSize>
      <acceptance>
        <Strict/>
      </acceptance>
      <constant name='const'>3.14</constant>
    </GradientDescent>
  </Optimizers>

  <Models>
    <ExternalModel ModuleToLoad="../../../framework/AnalyticModels/optimizing/beale" name="beale" subType="">
      <variables>x,y,ans,aux_ans</variables>
    </ExternalModel>
  </Models>

  <DataObjects>
    <PointSet name="dummyIN"/>
    <PointSet name="optOut">
      <Input>x,y,func,const</Input>
      <Output>ans,aux_ans</Output>
    </PointSet>
    <PointSet name="opt_export">
      <Input>trajID</Input>
      <Output>x,y,func,const,ans,aux_ans,stepSize,iteration,accepted,conv_gradient</Output>
    </PointSet>
  </DataObjects>

  <OutStreams>
    <Print name="optOut">
      <type>csv</type>
      <source>optOut</source>
    </Print>
    <Print name="opt_export">
      <type>csv</type>
      <source>opt_export</source>
      <clusterLabel>trajID</clusterLabel>
    </Print>
    <Plot name="opt_path" subType="OptPath">
      <source>opt_export</source>
      <vars>x,y,func,const,ans</vars>
    </Plot>
  </OutStreams>

</Simulation>
