<?xml version="1.0" ?>
<Simulation verbosity="debug">
  <TestInfo>
    <name>framework/Optimizers.StochasticFiniteDifference</name>
    <author>alfoa</author>
    <created>2017-09-11</created>
    <classesTested>Optimizer.FiniteDifferenceGradientOptimizer</classesTested>
    <description>
      This test runs the optimization (Finite difference forward) on a inverse parabola with signal-to-noise ratio close to 1.0 using
      multiple gradient evaluations to denoise the response space.  It tests stochastic optimization mechanics.
    </description>
    <analytic>
      This tests uses the inverse parabola as a basis for the noisy optimization. The inverse parabola is documented
      in the analytic tests, and has an average optimal max point at $x=0$.
    </analytic>
  </TestInfo>
  <RunInfo>
    <WorkingDir>StochasticFiniteDifference</WorkingDir>
    <Sequence>optimize,getOptPoint,print</Sequence>
    <batchSize>1</batchSize>
  </RunInfo>

  <Steps>
    <MultiRun name="optimize">
      <Input class="DataObjects" type="PointSet">dummyIN</Input>
      <Model class="Models" type="ExternalModel">parabola</Model>
      <Optimizer class="Optimizers" type="SPSA">opter</Optimizer>
      <SolutionExport class="DataObjects" type="HistorySet">opt_export</SolutionExport>
      <Output class="DataObjects" type="PointSet">optOut</Output>
    </MultiRun>
    <IOStep name="print" pauseAtEnd="True">
      <Input class="DataObjects" type="PointSet">opt_soln</Input>
      <Input class="DataObjects" type="HistorySet">opt_export</Input>
      <Output class="OutStreams" type="Print">opt_soln</Output>
      <Output class="OutStreams" type="Print">opt_export</Output>
    </IOStep>
    <PostProcess name="getOptPoint">
      <Input class="DataObjects" type="HistorySet">opt_export</Input>
      <Model class="Models" type="PostProcessor">snapshot</Model>
      <Output class="DataObjects" type="PointSet">opt_soln</Output>
      <Output class="OutStreams" type="Print">opt_soln</Output>
    </PostProcess>
  </Steps>

  <Optimizers>
    <FiniteDifferenceGradientOptimizer name="opter">
      <initialization>
        <limit>2000</limit>
        <initialSeed>42</initialSeed>
        <type>max</type>
      </initialization>
      <TargetEvaluation class="DataObjects" type="PointSet">optOut</TargetEvaluation>
      <convergence>
          <gradientThreshold>1e-2</gradientThreshold>
          <gainGrowthFactor>1.</gainGrowthFactor>
          <gainShrinkFactor>1.25</gainShrinkFactor>
      </convergence>
      <variable name='x'>
        <upperBound>1</upperBound>
        <lowerBound>-1</lowerBound>
        <initial>-0.75</initial>
      </variable>
      <objectVar>ans</objectVar>
      <parameter>
        <numGradAvgIterations>26</numGradAvgIterations>
      </parameter>
    </FiniteDifferenceGradientOptimizer>
  </Optimizers>

  <Models>
    <Dummy name="MyDummy" subType=""/>
    <ExternalModel ModuleToLoad="../Stochastic/stoch_parabola" name="parabola" subType="">
      <variables>x,ans,reg</variables>
    </ExternalModel>
    <PostProcessor name="snapshot" subType="InterfacedPostProcessor">
      <method>HistorySetSnapShot</method>
      <type>max</type>
      <pivotVar>varsUpdate</pivotVar>
    </PostProcessor>
  </Models>

  <DataObjects>
    <PointSet name="dummyIN">
      <Input>x</Input>
      <Output>OutputPlaceHolder</Output>
    </PointSet>
    <PointSet name="optOut">
      <Input>x</Input>
      <Output>ans,reg</Output>
    </PointSet>
    <PointSet name="opt_soln">
      <Input>trajID</Input>
      <Output>x,ans,reg,varsUpdate</Output>
    </PointSet>
    <HistorySet name="opt_export">
      <Input>trajID</Input>
      <Output>x,ans,reg,varsUpdate</Output>
    </HistorySet>
  </DataObjects>

  <OutStreams>
    <Print name="opt_export">
      <type>csv</type>
      <source>opt_export</source>
    </Print>
    <Print name="opt_soln">
      <type>csv</type>
      <source>opt_soln</source>
    </Print>
  </OutStreams>

</Simulation>
