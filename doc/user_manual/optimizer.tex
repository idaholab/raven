\section{Optimizers}
\label{sec:Optimizers}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% If you are confused by the input of this document, please make sure you see
% these defined commands first. There is no point writing the same thing over
% and over and over and over and over again, so these will help us reduce typos,
% by just editing a template sentence or paragraph.
\renewcommand{\nameDescription}
{
  \xmlAttr{name},
  \xmlDesc{required string attribute}, user-defined name of this optimizer.
  \nb As with other objects, this identifier can be used to reference this
  specific entity from other input blocks in the XML.
}
\renewcommand{\specBlock}[2]
{
  The specifications of this optimizer must be defined within #1 \xmlNode{#2} XML
  block.
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The optimizer is another important entity in the RAVEN framework. It performs the driving of a specific goal function
over the model for value optimization. The difference between an optimizer and a sampler is that the former does not require
 sampling over a distribution, although certain specific optimizers may utilize stochastic approach to locate the optimality.
The optimizers currently available in RAVEN can be categorized into the following class(es):
\begin{itemize}
\item \textbf{Gradient Based Optimizer} (see Section~\ref{subsec:gradientBasedOptimizers})
\end{itemize}

Before analyzing each optimizer in detail, it is important to mention that each type needs to be contained in the main XML
node \xmlNode{Optimizers}, as reported below:

\textbf{Example:}

\begin{lstlisting}[style=XML]
<Simulation>
  ...
  <Optimizers>
    ...
    <WhatEverOptimizer name='whatever'>
      ...
    </WhatEverOptimizer>
    ...
  </Optimizers>
  ...
</Simulation>
\end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%
%%%      Gradient Based Optimizers      %%%
%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Gradient Based Optimizers}
\label{subsec:gradientBasedOptimizers}
The Gradient Based Optimizer category collects all the strategies that perform the optimization based on gradient information,
 either directly provided or estimated by optimization strategy. In the RAVEN framework, currently implemented optimizer in this
 category are:
\begin{itemize}
\item \textbf{Simultaneous Perturbation Stochastic Approximation (SPSA)}
\end{itemize}

From a practical point of view, these optimization strategies represent different ways to estimate the gradient based on information
from previously performed model evaluation. In the following paragraphs, the input requirements and a small explanation of the
different sampling methodologies are reported.

Note that in addition to the input variables and response variable, several other parameters are available to
request for the output of a Gradient-Based Optimizer run.  Note that each starts with an underscore.  They include the following:
\begin{itemize}
  \item \xmlString{\_stepSize}, is the step size used to go from the previous optimal point to the current step;
  \item \xmlString{\_gradient\_var}, where \emph{var} is replaced by an input variable name, provides the
    gradient in the \emph{var} direction followed to arrive at the current optimal point (evaluated at the
    previous optimal point);
  \item \xmlString{\_convergence\_rel}, the last-calculated relative convergence of the loss function value
    (see the description of the \xmlNode{convergence} node for more details);
  \item \xmlString{\_convergence\_abs}, the last-calculated absolute convergence of the loss function value
    (see the description of the \xmlNode{convergence} node for more details);
  \item \xmlString{\_convergence\_grad}, the last-calculated norm of the gradient used to arrive at the
    current point (see the description of the \xmlNode{convergence} node for more details).
\end{itemize}
Note that none of these additional parameters will be provided to the output DataObject by default; they must
be specifically requested by listing them in the output space when defining the optimizing step's output data
object.

Example:
\begin{lstlisting}[style=XML]
<Optimizers>
  ...
  <AnyGradientBasedOptimizer name="anyname">
    <initialization>
      <limit>300</limit>
    </initialization>
    <TargetEvaluation class="DataObjects" type="PointSet">TEdataObjectName</TargetEvaluation>
    <convergence>
      <iterationLimit>50</iterationLimit>
      <relativeThreshold>1e-3</relativeThreshold>
      <absoluteThreshold>1e-1</absoluteThreshold>
      <gradientThreshold>1e-5</gradientThreshold>
    </convergence>
    <parameter>
      <numGradAvgIterations>3</numGradAvgIterations>
      <normalize>False</normalize>
    </parameter>
    <variable name="var1">
      <upperBound>100</upperBound>
      <lowerBound>-100</lowerBound>
      <initial>0</initial>
    </variable>
    <objectVar>c</objectVar>
  </SPSA>
  ...
</Optimizers>

%%% Gradient Based Optimizers: SPSA
\subsubsection{Simultaneous Perturbation Stochastic Approximation (SPSA)}
\label{subsubsubsec:SPSA}
The \textbf{SPSA} optimization approach is one of the optimization strategies that are based on gradient estimation. The main
idea is to simultaneously perturb all decision variables in order to estimate the gradient. Consequently a minimal number of two
model evaluations are required in order to approximate the gradient. The theory behind SPSA can be found in
\cite{spall1998implementation}.

In addition to the algorithm in \cite{spall1998implementation}, current implementation of \textbf{SPSA} can also handles
constrained optimization problem. This paragraph briefly describes how current implementation ensures the input satisfies the
constraints. When when updating the variables (not perturbing), if constraint is violated, \textbf{SPSA} does the following in
sequence:
\begin{itemize}
\item Try to find, through bisection method, the longest fraction of gradient vector so that the variable update satisfies the
constraints;
\item When such fraction cannot be found, then find a random vector orthogonal to gradient vector so that, by using this
orthogonal vector as gradient, the variable update satisfies the constraints. Rotate the orthogonal vector towards the gradient,
through bisection methods, until constraints can no longer be satisfied;
\item If all above cannot return a constraint satisfying variable update, then do not update the variables and the \textbf{SPSA} will
terminate.
\end{itemize}

It is important to notice that the gradient and the feature space is always normalized. This means that the gradient is going to be
normalized with respect to its norm (versor of the gradient); hence, the optimization advancement is not going to be influenced by the
magnitude of the gradient, but just on its ``direction'' information content. All the following parameters that can be optionally be inputted
should be calibrated with this information in mind.
%

\specBlock{a}{SPSA}
%
\attrsIntro
\vspace{-5mm}
\begin{itemize}
\itemsep0em
\item \xmlAttr{name}, \xmlDesc{required string attribute}, user-defined name of this optimizer. \nb As for the other objects, this is
the name that can be used to refer to this specific entity from other input blocks (xml);
\end{itemize}
\vspace{-5mm}

In the \xmlNode{SPSA} input block, the user needs to specify the objective variable to be optimized, the decision variables, the
DataObject storing previously performed model evaluation, as well as convergence criteira. In addition, the settings for this
optimization can be specified in the \xmlNode{initialization} and \xmlNode{parameter} XML blocks:
\begin{itemize}
\item \xmlNode{initialization},  \xmlDesc{XML node, optional parameter}. In this xml-node,the following xml sub-nodes can be
specified:
  \begin{itemize}
    \item \xmlNode{limit}, \xmlDesc{integer,optional field}, number of samples to be generated, which is same as the number of
    model evaluation. \default{2000}.
    \item \xmlNode{initialSeed}, \xmlDesc{integer, optional field}, initial seeding of random number generator for stochastic
    perturbations;
    \item \xmlNode{type},  \xmlDesc{string (case insensitive), optional field}, specifies whether this optimizer performs maximization
    or minimization. Available options are \xmlString{max} and \xmlString{min}.
    \default{Min};
    \item \xmlNode{thresholdTrajRemoval}, \xmlDesc{float, optional field}, this will be used to determine the convergence of different
    optimization trajectories when multiple trajectories is handled by \xmlNode{SPSA}.
    \default{0.05}
  \end{itemize}
\end{itemize}
\begin{itemize}
\item \xmlNode{Function}, \xmlDesc{XML node, optional parameter},
        indicates the external function where the constraints are stored. From a practical point of view, this XML node must contain the
        name of a function defined in the \xmlNode{Functions} block (see Section~\ref{sec:functions}). This external function must
        contain a method called ``constrain'', which returns 1 for inputs satisfying the constraints and 0 otherwise. When this block is
        absent and all the \xmlNode{upperBound} blocks of \xmlNode{variable} are absent (see below), then \xmlNode{SPSA} considers
        it as an unconstrained optimization problem;
\item \xmlNode{TargetEvaluation}, \xmlDesc{XML node, required parameter},
        represents the container where the model evaluations are stored.
        %
        From a practical point of view, this XML node must contain the name of
        a data object defined in the \xmlNode{DataObjects} block (see
        Section~\ref{sec:DataObjects}). The object here specified must be
        input as  \xmlNode{Output} in the Steps that employ this optimization strategy.
        %
        The \xmlNode{SPSA} optimizer accepts ``DataObjects'' of type ``PointSet'' only;
\item \xmlNode{objectVar}, \xmlDesc{XML node, required parameter}. The objective variable to be optimized. This variable must be
output of the DataObject specified in \xmlNode{TargetEvaluation}.
\end{itemize}
\begin{itemize}
\item \variableDescription
 The variable specified here must be input of the DataObject specified in \xmlNode{TargetEvaluation}.
 \variableChildrenIntro
 \begin{itemize}
    \item \xmlNode{upperBound}, \xmlDesc{float, required field}, the upper bound of this variable;
    \item \xmlNode{lowerBound}, \xmlDesc{float, required field}, the lower bound of this variable;
    \item \xmlNode{initial}, \xmlDesc{comma separated strings, optional field}, the initial value(s) for this variable. If there are more
    than one initial values specified for a variable, then all the variables need to have the same number of initial values. In this case,
    \xmlNode{SPSA} optimizer will maintain multiple trajectories to fully utilize potential parallel computing capability.
    \default{Mean of the \xmlNode{upperBound} and \xmlNode{lowerBound}}
  \end{itemize}
\end{itemize}
\constantVariablesDescription
\begin{itemize}
\item \xmlNode{convergence}, \xmlDesc{XML node, optional parameter} will specify parameters associated with optimization
convergence. This node accepts the following sub-nodes:
  \begin{itemize}
  \item \xmlNode{iterationLimit}, \xmlDesc{integer, optional field}, user-defined maximum number of optimization iterations. \default{650}.
  \item \xmlNode{relativeThreshold}, \xmlDesc{float, optional field}, specifies the convergence criteria to determine the optimality
  in a ``relative'' sense: when the relative change of the objective variable in two successive model evaluations is smaller than
  this specified threshold, the \xmlNode{SPSA} optimizer is in convergence and terminates the simulation.
      \default{1e-3}
  \item \xmlNode{absoluteThreshold}, \xmlDesc{float, optional field}, specifies the convergence criteria to determine the optimality,
  in an ``absolute'' sense: when the absolute change of objective variable in two successive model evaluations is smaller
  than this specified threshold, the \xmlNode{SPSA} optimizer is in convergence and terminates the simulation.
      \default{0.0}
   \item \xmlNode{gradientThreshold}, \xmlDesc{float, optional field}, specifies the convergence criteria to determine the optimality,
   as function of the L2 norm of the gradient (useful for unconstrained problems): when the L2 norm od the gradient falls below this threshold, the \xmlNode{SPSA} optimizer is in convergence and terminates the simulation.
      \default{1e-3}
  \end{itemize}
\item \xmlNode{parameter}, \xmlDesc{XML node, optional parameter} will accepts the following sub-nodes:
  \begin{itemize}
  \item \xmlNode{numGradAvgIterations}, \xmlDesc{integer, optional field} is the number of iterations for gradient estimation. When this
        parameter is $>1$, multiple gradient evaluations are going to be performed. Since the main goal for this parameter is to
        get a better gradient estimation (performing a denoising), the current point $x_k$ is evaluated multiple times in order to be able to
        converge in average.
        \default{1}

  \item Optimizer Gradient Evaluation parameters:
    \begin{itemize}
      \item \xmlNode{gamma}, \xmlDesc{float, optional field} Inverse exponent for gradient evaluation distance. Increasing this
        parameter will greatly decrease the distance between points sampled in evaluating the gradient
        \cite{spall1998implementation}. A practical suggestion for $\gamma$ is 0.101 (paired with an
        $\alpha$ value of 0.602); however, the asymptotic limit is $\gamma=1/6$ ($\alpha=1$). \default{0.101}
      \item \xmlNode{c}, \xmlDesc{float, optional field} Step size coefficient.  This term determines the
        nominal step size, and increasing it will directly increase the distance between points sampled in evaluating the gradient
        \cite{spall1998implementation}. It is suggested this parameter be approximately equal to the standard
        deviation of the measurement noise in the response for stochastic responses.  For regular responses,
        it can be a small arbitrary value. \default{0.005}
    \end{itemize}

  \item Optimizer Step Size parameters:
    \begin{itemize}
      \item \xmlNode{a}, \xmlDesc{float, optional field} Nominal optimizer step size parameter.  Increasing
        this parameter will directly increase the distance traversed in each optimizer step
        \cite{spall1998implementation}. In contrast to $A$, this parameter will be unchanged by increasing
        iterations, and so will be more impacting as the optimization algorithm iterates. \default{0.16}
      \item \xmlNode{alpha}, \xmlDesc{float, optional field} Inverse exponent for optimizer step size.
        Increasing this parameter will greatly decrease the distance traversed in each optimizer step
        \cite{spall1998implementation}. Values less than 1 for $\alpha$ usually yield better performance by
        keeping a large step size. See the description of $\gamma$ above for some suggested values. \default{0.602}
      \item \xmlNode{A}, \xmlDesc{float, optional field} Nominal step damping stability parameter.  Increasing this
        parameter will directly decrease the distance traversed in each optimizer step
        \cite{spall1998implementation}. This parameter will have greater affect in reducing step size early in
        the calculation, and reduced affect as iterations increase. \default{\xmlNode{limit} divided by 10}
    \end{itemize}
  \item \xmlNode{innerBisectionThreshold}, \xmlDesc{float, optional field} a parameter specifying the convergence threshold of the
  bisection method used in constraint handling (See above). This parameter shall be in the open inverval $(0,1)$.
        \default{0.01}
  \item \xmlNode{innerLoopLimit}, \xmlDesc{integer, optional field} a parameter specifying the number of orthogonal vectors to try
  when handling the constraints (See above).
        \default{1000}
  \end{itemize}
\end{itemize}


Example:
\begin{lstlisting}[style=XML]
<Optimizers>
  ...
  <SPSA name="SPSAname">
    <initialization>
      <limit>300</limit>
      <type>min</type>
      <initialSeed>30</initialSeed>
    </initialization>
    <TargetEvaluation class="DataObjects" type="PointSet">dataObjectName</TargetEvaluation>
    <convergence>
      <iterationLimit>50</iterationLimit>
      <relativeThreshold>1e-3</relativeThreshold>
      <absoluteThreshold>1e-1</absoluteThreshold>
      <gradientThreshold>1e-5</gradientThreshold>
    </convergence>
    <parameter>
      <numGradAvgIterations>3</numGradAvgIterations>
      <normalize>False</normalize>
    </parameter>
    <variable name="var1">
      <upperBound>100</upperBound>
      <lowerBound>-100</lowerBound>
      <initial>0</initial>
    </variable>
    <objectVar>c</objectVar>
  </SPSA>
  ...
</Optimizers>
\end{lstlisting}
