\subsubsection{Validation PostProcessors}
\label{subsubsec:Validation}

The \textbf{Validation} PostProcessors represent a group of validation methods
for applying a different range of algorithms to validate (e.g. compare)
dataset and/or models (e.g. Distributions).

Several post-processors are available for model validation:
\begin{itemize}
  \item  \textbf{Probabilistic}, using probabilistic method for validation, can be used for both static and time-dependent problems.
  \item  \textbf{PPDSS}, using dynamic system scaling method for validation, can only be used for time-dependent problems.
  \item  \textbf{Representativity}, using represntativity (bias) factor for validation, currently, can be used for static data.
  \item  \textbf{PCM}, using Physics-guided Coverage Mapping method for validation, can be used for static and time-dependent problems.
\end{itemize}
%

The choices of the available metrics and acceptable data objects are specified in table \ref{tab:ValidationAlgorithms}.

\begin{table}[]
\caption{Validation Algorithms and respective available metrics and DataObjects}
\label{tab:ValidationAlgorithms}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Validation Algorithm} & \textbf{DataObject}                                            & \textbf{Available Metrics}                                                   \\ \hline
Probabilistic                 & \begin{tabular}[c]{@{}c@{}}PointSet \\ HistorySet\end{tabular} & \begin{tabular}[c]{@{}c@{}}CDFAreaDifference\\ \\ PDFCommonArea\end{tabular} \\ \hline
Representativity              & \begin{tabular}[c]{@{}c@{}}PointSet \\ HistorySet \\DataSet\end{tabular} & \begin{tabular}[c]{@{}c@{}}\end{tabular} \\ \hline
PPDSS                         & HistorySet                                                     & DSS                                                           \\ \hline
\end{tabular}
\end{table}

These post-processors can accept multiple \textbf{DataObjects} as inputs. When multiple DataObjects are provided,
The user can use $DataObjectName|InputOrOutput|VariableName$ nomenclature to specify the variable
in \xmlNode{Features} and \xmlNode{Targets} for comparison.

\paragraph{Probabilistic}
The \textbf{Probabilistic} specify that the validation needs to be performed
using the Probabilistic metrics: \textbf{CDFAreaDifference} (see \ref{subsubsec:metric_CDFAreaDifference})
or \textbf{PDFCommonArea} (see \ref{subsubsec:metric_PDFCommonArea})

%
\ppType{Probabilistic}{Probabilistic}
%

\begin{itemize}
  \item \xmlNode{Features}, \xmlDesc{comma separated string, required field}, specifies the names of the features.
  \item \xmlNode{Targets}, \xmlDesc{comma separated string, required field}, contains a comma separated list of
    targets. \nb Each target is paired with a feature listed in xml node \xmlNode{Features}. In this case, the
    number of targets should be equal to the number of features.
  \item \xmlNode{pivotParameter}, \xmlDesc{string, required field if HistorySet is used}, specifies the pivotParameter for a <HistorySet>.
    The pivot parameter is the shared index of the output variables in the data object.
  \item \xmlNode{Metric}, \xmlDesc{string, required field}, specifies the \textbf{Metric} name that is defined via
    \textbf{Metrics} entity. In this xml-node, the following xml attributes need to be specified:
    \begin{itemize}
      \item \xmlAttr{class}, \xmlDesc{required string attribute}, the class of this metric (e.g., Metrics)
      \item \xmlAttr{type}, \xmlDesc{required string attribute}, the sub-type of this Metric (e.g., SKL, Minkowski)
    \end{itemize}
    \nb The choices of the available metrics are \xmlString{CDFAreaDifference} and \xmlString{PDFCommonArea}, please
    refer to \ref{sec:Metrics} for detailed descriptions about these metrics.
\end{itemize}

\textbf{Example:}
\begin{lstlisting}[style=XML,morekeywords={subType}]
<Simulation>
  ...
  <Metrics>
    <Metric name="cdf_diff" subType="CDFAreaDifference"/>
    <Metric name="pdf_area" subType="PDFCommonArea"/>
  </Metrics>
  ...
  <Models>
    ...
    <PostProcessor name="pp1" subType="Probabilistic">
      <Features>outputDataMC1|ans</Features>
      <Targets>outputDataMC2|ans2</Targets>
      <Metric class="Metrics" type="CDFAreaDifference">cdf_diff</Metric>
      <Metric class="Metrics" type="PDFCommonArea">pdf_area</Metric>
    </PostProcessor>
    ...
  <Models>
  ...
<Simulation>
\end{lstlisting}

\paragraph{PPDSS}
\textbf{PPDSS} specifies that the validation needs to be performed
using the PPDSS metrics: the dynamic system scaling metric, e.g., \textbf{DSS} (\ref{subsection:DSS}).

%
\ppType{PPDSS}{PPDSS}
%

\begin{itemize}
  \item \xmlNode{prototypeOutputs}, \xmlDesc{comma separated string, required field}, contains a comma separated list of strings specifying the names of the prototype/mock model outputs.
  \item \xmlNode{targetOutputs}, \xmlDesc{comma separated string, required field}, contains a comma separated list of
   strings specifying target outputs.
  \item \xmlNode{pivotParameter}, \xmlDesc{string, required field if HistorySet is used}, specifies the pivotParameter for a <HistorySet>.
    The pivot parameter is the shared index of the output variables in the data object.
  \item \xmlNode{Metric}, \xmlDesc{string, required field}, specifies the \textbf{Metric} name that is defined via
    \textbf{Metrics} entity. In this xml-node, the following xml attributes need to be specified:
    \begin{itemize}
      \item \xmlAttr{class}, \xmlDesc{required string attribute}, the class of this metric (e.g., Metrics)
      \item \xmlAttr{type}, \xmlDesc{required string attribute}, the sub-type of this Metric (e.g., SKL, Minkowski)
    \end{itemize}
    \nb The choice of the available metric is \xmlString{DSS}, please
    refer to \ref{sec:Metrics} for detailed descriptions about this metric.
    \item \xmlNode{pivotParameterFeature}, \xmlDesc{string, required field}, specifies the pivotParameter for a feature <HistorySet>. The feature pivot parameter is the shared index of the output variables in the data object.
    \item \xmlNode{pivotParameterTarget}, \xmlDesc{string, required field}, specifies the pivotParameter for a target <HistorySet>. The target pivot parameter is the shared index of the output variables in the data object.
    \item \xmlNode{multiOutput}, \xmlDesc{string, required field}, to extract raw values for the HistorySet. The user must use ‘raw values’ for the full set of metrics’ calculations to be dumped.
    \item \xmlNode{scale}, \xmlDesc{string, required field}, specifies the type of time scaling. The following are the options for scaling (specific definitions for each scaling type is provided in \ref{sec:dssdoc}):
      \begin{itemize}
        \item \textbf{DataSynthesis}, calculating the distortion for two data sets without applying other scaling ratios.
        \item \textbf{2\_2\_affine}, calculating the distortion for two data sets with scaling ratios for parameter of interest and agent of changes.
        \item \textbf{dilation}, calculating the distortion for two data sets with scaling ratios for parameter of interest and agent of changes.
        \item \textbf{beta\_strain}, calculating the distortion for two data sets with scaling ratio for parameter of interest.
        \item \textbf{omega\_strain}, calculating the distortion for two data sets with scaling ratios for agent of changes.
        \item \textbf{identity}, calculating the distortion for two data sets with scaling ratios of 1.
      \end{itemize}
    \item \xmlNode{scaleBeta}, \xmlDesc{float or comma separated list of floats, required field}, specifies the parameter of interest scaling ratio between the feature and target.
    To provide more than one scaling factor, separate by adding a comma in between each number. Providing more than one scaling factor presumes there are more than one parameter to be post-processed.
    If so, \xmlNode{Features}, \xmlNode{Targets}, and \xmlNode{scaleOmega} must have the same number scaling factors.
    \item \xmlNode{scaleOmega}, \xmlDesc{float or comma separated list of floats, required field}, specifies the agents of change scaling ratio between the feature and target.
    To provide more than one scaling factor, separate by adding a comma in between each number. Providing more than one scaling factor presumes there are more than one parameter to be post-processed.
    If so, \xmlNode{Features}, \xmlNode{Targets}, and \xmlNode{scaleBeta} must have the same number scaling factors.
\end{itemize}

\textbf{Example:}
\begin{lstlisting}[style=XML,morekeywords={subType}]
<Simulation>
  ...
  <Metrics>
    <Metric name="dss" subType="DSS"/>
  </Metrics>
  ...
  <Models>
    ...
    <PostProcessor name="pp2" subType="PPDSS">
      <Features>outMC1|x1,outMC1|y1</Features>
      <Targets>outMC2|x2,outMC2|y2</Targets>
      <Metric class="Metrics" type="Metric">dss</Metric>
      <pivotParameterFeature>time1</pivotParameterFeature>
      <pivotParameterTarget>time2</pivotParameterTarget>
      <scale>DataSynthesis</scale>
      <scaleBeta>1,1</scaleBeta>
      <scaleOmega>1,1</scaleOmega>
    </PostProcessor>
    ...
  <Models>
  ...
<Simulation>
\end{lstlisting}

\paragraph{Representativity}
The \textbf{Representativity} post-processor is one of three \textbf{Validation} post-processors, in fact there is a
post-processor interface that acts as a gate for applying these validation algorithms
(i.e., representativity, Physics-guided Convergence Mapping (PCM), and Dynamic System Scaling (DSS)).
The post-processor is in charge of deploying a common infrastructure for the user of  \textbf{Validation} problems.
%The usage of this post-processor is three fold. one, to quantitatively assess if a mock/prototype model/experiment
%form a good representation of a target model. Two, if  a set of experiments can represent a target model and can
%claim a full coverage of the design space and scenarios, and three, if the available set of experiments are not
%enough to declare coverage what are the remaining experiments required in order to achieve full coverage and
%increase the representativity/bias factor.
The representativity theory was first founded in the
Neutronics community \cite{Gandini, palmiotti1, palmiotti2}, then lately, was transformed to the thermal hydraulics \cite{Epiney1, Epiney2}. So far, several algorithms are implemented within this post-processor:
%
\ppType{Representativity}{Representativity}
%

\begin{itemize}
  \item \xmlNode{Features}, \xmlDesc{comma separated string, required field}, specifies the names of  the features, which can be the measuables/observables of the mock model. Reader should be warned that this nomenclature is different than the Machine learning nomenclature.

  \item \xmlNode{Targets}, \xmlDesc{comma separated string, required field}, contains a comma separated list of
     targets. These are the Figures of merit (FOMs) in the target model against which the mock model is being validated.

    \item \xmlNode{featureParameters}, \xmlDesc{comma separated string, required field}, specifies the names of  the parameters/inputs to the mock model.

    \item \xmlNode{targetParameters}, \xmlDesc{comma separated string, required field}, contains a comma separated list of
    target parameters/inputs.

        \item \xmlNode{pivotParameter},  \xmlDesc{string, optional field}, ID of the temporal variable of the mock model. Default is ``time''.
        \nb Used just in case the  \xmlNode{pivotValue}-based operation  is requested (i.e., time dependent validation).
        \item \xmlNode{targetPivotParameter}, \xmlDesc{string, optional field}, ID of the temporal variable in the target model. Default is ``time''.
        \nb Used just in case the  \xmlNode{pivotValue}-based operation  is requested (i.e., time dependent validation).
\end{itemize}


The \textbf{Represntativity} post-processor can make use of the \textbf{Metric} system (See Chapter \ref{sec:Metrics}),
in conjunction with the specific algorithm chosen from the list above,
to report validation scores for both static and time-dependent data.
Indeed, Both \textbf{PointSet} and \textbf{HistorySet} can be accepted by this post-processor.
If the name of given variable to be compared is unique, it can be used directly, otherwise the variable can be specified
with $DataObjectName|InputOrOutput|VariableName$ nomenclature.

The \xmlNode{Output} node of the \xmlNode{PointSet} the \xmlNode{Representativity} Postprocessor, accepts outputs like:
\begin{itemize}
  \item BiasFactor\_Mock\{prototype output $var_i$  name\}\_Tar\{target output $var_j$ name\}:

    representativity or bias factor of prototype output (measurable) i with respect to target j

    	assuming no measurement uncertainty in the mock model

    	 (i.e., BiasFactor\_MockF1\_TarFOM2).

  \item ExactBiasFactor\_Mock\{prototype output $var_i$ name\}\_Tar\{target output $var_j$ name\}:

   representativity or bias factor of prototype output (measurable) i with respect to target j

    considering measurements uncertainty in the mock model

     (i.e., ExactBiasFactor\_MockF1\_TarFOM2).

  \item CorrectedParameters\_\{parameter output $var_i$ name\}:

  the adjusted/corrected value of parameter i due to the analysis

  (i.e., CorrectedParameters\_p1)

  \item CorrectedTargets\_{output $var_i$ name}:

  the adjusted/corrected value of  target i due to the analysis

  (i.e., CorrectedTargets\_FOM1)

  \item VarianceInCorrectedParameter\_\{parameter output $var_i$ name\}:

 variance in corrected parameter i (squared uncertainty)

  (i.e., VarianceInCorrectedParameter\_p1)

  \item CovarianceInCorrectedParameters\_\{parameter $var_i$ name\}\_\{parameter $var_j$ name\}:

 Covariance between parameter i and parameter j

 (i.e., CovarianceInCorrectred\_p1)

  \item CorrectedVar\_Tar\{target $vat_i$ name\}:

   variance in corrected target i

   (i.e., CorrectedVar\_TarFOM1)

  \item ExactCorrectedVar\_Tar\{target $var_i$ name\}:

  exact variance in corrected target i considering uncertainty in measurements in the mock model.

  (i.e., ExactCorrectedVar\_TarFOM1)

  \item CorrectedCov\_Tar\{target $var_i$ name\}\_Tar\{target $var_j$ name\}:

  covariance between corrected target i and corrected target j

  (i.e., CorrectedCov\_TarFOM1)

  \item ExactCorrectedCov\_Tar\{target $var_i$ name\}\_Tar\{target $var_j$ name\}

   exact covariance between corrected target i and corrected target j considering uncertainties in measurements in the mock model.

   (i.e., ExactCorrectedCov\_TarFom1\_TarFOM2)

\nb{all variable names proceeded by 'Exact' takes into account the measurement uncertainties in the mock experiment}

\end{itemize}


\paragraph{PCM}
\textbf{PCM} evaluates the uncertainty reduction fraction and obtain posterior distribution of Target
when using Feature(s) to validate each Target via Physics-guided Coverage Mapping (PCM) method. There are
three versions of PCM so far: `Static', `Snapshot', and `Tdep'. Static PCM is for static problem, and Snapshot PCM
and Tdep PCM are for time-dependent problem.

\begin{itemize}
  \item \xmlNode{pivotParameter}, \xmlDesc{string, optional field}, defaulted as `time', and required by Snapshot and Tdep PCM.
  \item \xmlNode{Features}, \xmlDesc{comma separated string, required field}, specifies the names of the features.
  \item \xmlNode{Targets}, \xmlDesc{comma separated string, required field}, contains a comma separated list of
     targets. \nb Each target will be validated using all features listed in xml node \xmlNode{Features}. The
    number of targets is not necessarily equal to the number of features.
  \item \xmlNode{Measurements}, \xmlDesc{comma separated string, required field}, contains a comma separated list of
     measurements of the features. \nb Each measurement correspond to a feature listed in xml node \xmlNode{Features}. The
    number of measurements should be equal to the number of features and in the same order as the features listed in \xmlNode{Features}.
  \item \xmlNode{pcmType}, \xmlDesc{string, required field}, contains the string given by users to choose the version
    of PCM to be applied. \nb It has three options: `Static', `Snapshot', and `Tdep', corresponding to the three PCM versions.
  \item \xmlNode{ReconstructionError}, \xmlDesc{float, optional field}, contains the value given by users to determind the
    reconstruction error corresponding to rank of time series data. Default value is 0.001 if not given.
\end{itemize}

The output of Static PCM is comma separated list of strings in the format of ``pri\textunderscore post\textunderscore stdReduct\textunderscore [targetName]'',
where [targetName] is the $VariableName$ specified in DataObject of \xmlNode{Targets}.
The output of Snapshot PCM includes two comma separated lists ``time'' and  ``snapshot\textunderscore pri\textunderscore post\textunderscore stdReduct'',
which corresponding to the timesteps and uncertainty reduction fraction of the time-series Target data specified in DataObject of \xmlNode{Targets}.
The output of Tdep PCM includes three comma separated lists ``time'', ``Tdep\textunderscore post\textunderscore mean'', and ``Error'',
which corresponding to the timesteps, posterior mean, and error between posterior and prior Target data specified in DataObject of \xmlNode{Targets}.

\textbf{Example: Static PCM}
\begin{lstlisting}[style=XML,morekeywords={subType}]
<Simulation>
...
  <Steps>
    <MultiRun name="mcRun" re-seeding="20021986">
	  <Input class="DataObjects" type="PointSet">inputPlaceHolder2</Input>
	  <Model class="Models" type="ExternalModel">linModel</Model>
	  <Sampler class="Samplers" type="MonteCarlo">MC_external</Sampler>
	  <Output class="DataObjects" type="PointSet">outputDataMC1</Output>
	  <Output class="DataObjects" type="PointSet">outputDataMC2</Output>
	</MultiRun>
	<PostProcess name="PP1">
	  <Input class="DataObjects" type="PointSet">outputDataMC1</Input>
	  <Input class="DataObjects" type="PointSet">outputDataMC2</Input>
	  <Model class="Models" type="PostProcessor">pp1</Model>
	  <Output class="DataObjects" type="PointSet">pp1_metric</Output>
	  <Output class="OutStreams" type="Print">pp1_metric_dump</Output>
	</PostProcess>
  </Steps>
...
  <Models>
...
	<PostProcessor name="pp1" subType="Representativity">
	  <Features>outputDataMC1|F1, outputDataMC1|F2, outputDataMC1|F3</Features>
	  <Targets>outputDataMC2|F1, outputDataMC2|F2, outputDataMC2|F3</Targets>
	  <featureParameters>outputDataMC1|p1,outputDataMC1|p2</featureParameters>
	  <targetParameters>outputDataMC2|p1,outputDataMC2|p2</targetParameters>
	  <pivotParameter>outputDataMC1|time</pivotParameter>
	</PostProcessor>
...
<Models>
...
<PointSet name="pp1_metric">
  <Input>InputPlaceHolder</Input>
  <Output>
    BiasFactor_MockF1_TarFOM1,
    BiasFactor_MockF1_TarFOM2,
    BiasFactor_MockF1_TarFOM3,
    BiasFactor_MockF2_TarFOM1,
    BiasFactor_MockF2_TarFOM2,
    BiasFactor_MockF2_TarFOM3,
    BiasFactor_MockF3_TarFOM1,
    BiasFactor_MockF3_TarFOM2,
    BiasFactor_MockF3_TarFOM3,
    ExactBiasFactor_MockF1_TarFOM1,
    ExactBiasFactor_MockF1_TarFOM2,
    ExactBiasFactor_MockF1_TarFOM3,
    ExactBiasFactor_MockF2_TarFOM1,
    ExactBiasFactor_MockF2_TarFOM2,
    ExactBiasFactor_MockF2_TarFOM3,
    ExactBiasFactor_MockF3_TarFOM1,
    ExactBiasFactor_MockF3_TarFOM2,
    ExactBiasFactor_MockF3_TarFOM3,
    CorrectedParameters_p1,
    CorrectedParameters_p2,
    CorrectedTargets_FOM1,
    CorrectedTargets_FOM2,
    CorrectedTargets_FOM3,
    VarianceInCorrectedParameters_p1,
    VarianceInCorrectedParameters_p2,
    CovarianceInCorrectedParameters_p1_p2,
    CovarianceInCorrectedParameters_p2_p1,
    CorrectedVar_TarFOM1,
    CorrectedVar_TarFOM2,
    CorrectedVar_TarFOM3,
    ExactCorrectedVar_TarFOM1,
    ExactCorrectedVar_TarFOM2,
    ExactCorrectedVar_TarFOM3,
    CorrectedCov_TarFOM1_TarFOM2,
    CorrectedCov_TarFOM2_TarFOM1,
    CorrectedCov_TarFOM1_TarFOM3,
    CorrectedCov_TarFOM3_TarFOM1,
    CorrectedCov_TarFOM2_TarFOM3,
    CorrectedCov_TarFOM3_TarFOM2,
    ExactCorrectedCov_TarFOM1_TarFOM2,
    ExactCorrectedCov_TarFOM2_TarFOM1,
    ExactCorrectedCov_TarFOM1_TarFOM3,
    ExactCorrectedCov_TarFOM3_TarFOM1,
    ExactCorrectedCov_TarFOM2_TarFOM3,
    ExactCorrectedCov_TarFOM3_TarFOM2
  </Output>
</PointSet>
...
<Simulation>
\end{lstlisting}

\textbf{Example: Snapshot PCM}
\begin{lstlisting}[style=XML,morekeywords={subType}]
<Simulation>
  ...
  <Models>
    ...
    <PostProcessor name="pcm_snapshot" subType="PhysicsGuidedCoverageMapping">
      <pivotParameter>time</pivotParameter>
      <Features>exp|TempC</Features>
      <Targets>app|TempD</Targets>
      <Measurements>msr|TempMsrC</Measurements>
      <pcmType>Snapshot</pcmType>
    </PostProcessor>
    ...
  <Models>
  ...
<Simulation>
\end{lstlisting}

\textbf{Example: Tdep PCM}
\begin{lstlisting}[style=XML,morekeywords={subType}]
<Simulation>
  ...
  <Models>
    ...
    <PostProcessor name="pcm_Tdep" subType="PhysicsGuidedCoverageMapping">
      <pivotParameter>time</pivotParameter>
      <Features>exp|TempC</Features>
      <Targets>app|TempD</Targets>
      <Measurements>msr|TempMsrC</Measurements>
      <pcmType>Tdep</pcmType>
      <ReconstructionError>0.001</ReconstructionError>
    </PostProcessor>
    ...
  <Models>
  ...
<Simulation>
\end{lstlisting}
